# -*- coding: utf-8 -*-
"""ST_Benchmarking_different_imputation_methods-v2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uGLz8gziT4P6iQj6FOHFyYJeOtXq9kwx

Different Imputation methods:
1) https://www.scrna-tools.org/tools?sort=name&cats=Imputation
2) https://github.com/scRNA-tools/scRNA-tools
3) From Literatures:
   a) SAVER b) scImpute c) deepImpute d) PRIME e) bayNorm f) KNN-smoothing
   g) McImpute h) scrabble i) scRMD j) Mcimpute-block k) FEATS

Implemented Imputation Methods:
1) MAGIC
2) Similar like ALRA
3) KNN Imputation


Failed Imputation Methods:
1) scVI (Takes too much time as well as installation issues)
2) DCA (installation issue)
3) CarDEC (installation issue)
4) AutoImpute (takes too much time and crashes even for singleimpute of this method)~ https://kearnz.github.io/autoimpute-tutorials/
5)
"""

from google.colab import drive
drive.mount('/content/drive')

# @title installing packages
!pip install scanpy
!pip install magic-impute
!pip install igraph
!pip3 install leidenalg
# !pip install -U scvi-tools
# !pip install scArches
# !pip install dca
!pip install autoimpute

# !python3 -m pip install adobo --user

# @title importing packages
import os
import torch
import numpy as np
import pandas as pd
import scanpy as sc
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import metrics
import time
import psutil
from sklearn.metrics import normalized_mutual_info_score
import magic
from sklearn.impute import KNNImputer
from scipy.sparse.linalg import svds
# import scvi
# import scarches as sca
# import dca
from autoimpute.imputations import SingleImputer, MultipleImputer, MiceImputer
import tracemalloc

# Display Colab configuration
cpu_info = os.popen('cat /proc/cpuinfo').read()
ram_info = os.popen('cat /proc/meminfo').read()
print(f"Colab CPU:\n{cpu_info}")
print(f"Colab RAM:\n{ram_info}")

def calculate_sparsity(matrix):
    """Calculate the proportion of zero values in a matrix."""
    return np.mean(matrix == 0)*100

# @title Reading preprocessed ST Datasets

## Read spatial transcriptomics data--> h5ad Data

# Directories
# /content/drive/MyDrive/UIU/MSCSE/Thesis/05. Codes and Datasets/ST_datasets/visium/DLPFC/
# /content/drive/MyDrive/UIU/MSCSE/Thesis/05. Codes and Datasets/ST_datasets/stereo-seq/
# /content/drive/MyDrive/UIU/MSCSE/Thesis/05. Codes and Datasets/ST_datasets/xyz-seq/

# Datasets Name
"""
visium--> 151507_processed, 151508_processed, 151509_processed, 151510_processed, 151669_processed, 151670_processed, 151671_processed, 151672_processed, 151673_processed, 151674_processed, 151675_processed, 151676_processed

stereoseq--> FB2_D1_stereo-seq_processed.h5ad, DT2_D0_stereo-seq_processed.h5ad, DX6_D2_stereo-seq_processed

xyzseq--> GSM5009529_XYZeq_raw_processed
"""
dataset = 'FB2_D1_stereo-seq_processed'
dataset_path = '/content/drive/MyDrive/UIU/MSCSE/Thesis/05. Codes and Datasets/ST_datasets/stereo-seq/' + str(dataset) + '.h5ad'

n_top = 2000

# Load the Stereo-seq data
adata = sc.read_h5ad(dataset_path)
print(f"before selecting the top {n_top} genes: {adata}")

# Keep the top 2000 genes
sc.pp.highly_variable_genes(adata, flavor="seurat", n_top_genes=n_top)
adata = adata[:, adata.var['highly_variable']]

print(f"after selecting the top {n_top} genes: {adata}")

adata.obsm['spatial'].shape

# @title magic imputation

# Step 1: Perform MAGIC Imputation
adata_imputed = adata.copy()


# Start memory tracking
tracemalloc.start()

# Record the start time
start_time = time.time()

# Perform MAGIC imputation
adata_imputed.X = magic.MAGIC().fit_transform(adata_imputed.X)

# Record the end time
end_time = time.time()

# Get peak memory usage
current, peak = tracemalloc.get_traced_memory()
peak_memory_used = peak / (1024**2)  # Convert from bytes to MB

# Stop memory tracking
tracemalloc.stop()

# Calculate the runtime in seconds
runtime = end_time - start_time

# Step 2: Perform Clustering on normal gene expression and imputed gene expression
# original gene expression
sc.pp.pca(adata)
sc.pp.neighbors(adata)
sc.tl.umap(adata)
sc.tl.leiden(adata, key_added="clusters", directed=False, n_iterations=2)

# imputed gene expression
sc.pp.pca(adata_imputed)
sc.pp.neighbors(adata_imputed)
sc.tl.umap(adata_imputed)
sc.tl.leiden(adata_imputed, key_added="clusters_imputed_magic", directed=False, n_iterations=2)

# Step 3: Compute ARI
ARI_original = metrics.adjusted_rand_score(adata.obs['clusters'], adata.obs['annotation']) # CellType or annotation
ARI_imputed = metrics.adjusted_rand_score(adata_imputed.obs['clusters_imputed_magic'], adata.obs['annotation']) # CellType or annotation

# Calculate NMI
NMI_original = normalized_mutual_info_score(adata.obs['clusters'], adata.obs['annotation'])
NMI_imputed = normalized_mutual_info_score(adata_imputed.obs['clusters_imputed_magic'], adata.obs['annotation'])


print('ARI (Before Magic Imputation):', ARI_original)
print('ARI (After Magic Imputation):', ARI_imputed)
print('NMI (Before Magic Imputation):', NMI_original)
print('NMI (After Magic Imputation):', NMI_imputed)
print('Runtime (seconds):', runtime)
print(f"Peak memory used during MAGIC imputation: {peak_memory_used:.2f} MB")

# @title magic imputation sparsity

# Compute sparsity before and after imputation
sparsity_before = calculate_sparsity(adata.X)  # Convert sparse matrix to array if needed
sparsity_after = calculate_sparsity(adata_imputed.X)

print(f"Sparsity Before Imputation: {sparsity_before:.4f}")
print(f"Sparsity After Imputation: {sparsity_after:.4f}")

#@title ALRA Imputation

def alra_impute(X, k=20):
    X = np.array(X)
    mean = np.mean(X, axis=0)
    X_centered = X - mean
    U, s, Vt = svds(X_centered, k=k)
    X_reconstructed = np.dot(U, np.dot(np.diag(s), Vt)) + mean
    X_reconstructed[X_reconstructed < 0] = 0
    return X_reconstructed

# Start memory tracking
tracemalloc.start()

# Record the start time
start_time = time.time()

# Step 1: Perform MAGIC Imputation
adata_imputed = adata.copy()
print("Running ALRA imputation...")
adata_imputed.X = alra_impute(adata_imputed.X) # adata_imputed.X.toarray()


# Record the end time
end_time = time.time()

# Get peak memory usage
current, peak = tracemalloc.get_traced_memory()
peak_memory_used = peak / (1024**2)  # Convert from bytes to MB

# Stop memory tracking
tracemalloc.stop()

# Calculate the runtime in seconds
runtime = end_time - start_time

# Step 2: Perform Clustering on imputed gene expression

# imputed gene expression
sc.pp.pca(adata_imputed)
sc.pp.neighbors(adata_imputed)
sc.tl.umap(adata_imputed)
sc.tl.leiden(adata_imputed, key_added="clusters_imputed_alra", directed=False, n_iterations=2)

# Step 3: Compute ARI
ARI_original = metrics.adjusted_rand_score(adata.obs['clusters'], adata.obs['annotation']) # CellType or annotation
ARI_imputed = metrics.adjusted_rand_score(adata_imputed.obs['clusters_imputed_alra'], adata.obs['annotation']) # CellType or annotation

# Calculate NMI
NMI_original = normalized_mutual_info_score(adata.obs['clusters'], adata.obs['annotation'])
NMI_imputed = normalized_mutual_info_score(adata_imputed.obs['clusters_imputed_alra'], adata.obs['annotation'])


print('ARI (Before ALRA Imputation):', ARI_original)
print('ARI (After ALRA Imputation):', ARI_imputed)
print('NMI (Before ALRA Imputation):', NMI_original)
print('NMI (After ALRA Imputation):', NMI_imputed)
print('Runtime (seconds):', runtime)
print(f"Peak memory used during ALRA imputation: {peak_memory_used:.2f} MB")

# @title alra imputation sparsity

# Compute sparsity before and after imputation
sparsity_before = calculate_sparsity(adata.X)  # Convert sparse matrix to array if needed
sparsity_after = calculate_sparsity(adata_imputed.X)

print(f"Sparsity Before Imputation: {sparsity_before:.4f}")
print(f"Sparsity After Imputation: {sparsity_after:.4f}")